



1,如果是UMA，就被看作只有一个节点的NUMA系统;

2,struct mem_section 用一个二维数组指针管理，第一维大小固定(NR_SECTION_ROOTS=1024)，第二维个数是根据有几个1G的内存申请几个 SECTIONS_PER_ROOT=256大小；
	(先是申请1024个struct mem_section结构体指针大小内存(即可以管理1024个256G)，根据内存大小申请256个struct mem_section结构体大小内存(内存小于256G就申请一次256个struct mem_section结构体,内存在256~512之间就申请2次256个struct mem_section结构体))

	mem_section[0x400(NR_SECTION_ROOTS=1024)][0x100(SECTIONS_PER_ROOT)]							mem_section[0][1]来记录0x40000000~0x80000000范围的物理地址，nid(NUMA_id)为0

3,一个struct mem_section结构体管理1G内存,同时需要：
	3.1,32*8=256字节内存保存pageblock_flags,	用memblock申请内存，虚拟地址取内核分配的虚拟地址
	3.1,256K*64=16M内存维护每一个页的状态 section_mem_map(struct page),	用memblock申请内存，虚拟地址用VMEMMAP_START指定的虚拟内存

		一个struct mem_setion对应PAGES_PER_SECTION(256K)个page(4K) = 4K * 256K = 1G
		256Kg个struct page所占用的空间为256K*64=16M

4,先统计ZONE_DMA32内存，超过这部分的才会统计到ZONE_NORMAL,没有超过的话ZONE_NORMAL则为空;

5,以NUMA_id初始化对应的pg_data_t(pg_data_t)结构体,计算可以用大小；
	初始化其中的各个zone的结构体, 其重要的zone结构体中管理内存申请的配置： 
	1,pcp(pageset),只要是维护0位阶的内存页框，per-cpu内存(申请释放比较频繁)
	2,初始化free_area 2^0,2^1,2^2,,,保存2^n可用块的链表；
	3,初始化zone里所有也对应的struct page结构体(在(3)中申请的)；
	4,将所有页的内存配置为可移动的内存MIGRATE_MOVABLE



虚拟地址到物理地址的映射都是已页为单位，一般1页为4K(页内部连续线性物理地址映射到连续虚拟地址上)

======================================================================================

初始化伙伴系统相关数据结构：
	每个zone区域的free_area中所有free list链表初始化
	每个zone区域中所有的页框描述符struct page的初始化
	每个zone区域中的所有pageblock对应迁移类型的初始化
	内存分配时每个内存节点的优先级列表node_zonelists初始化
	每个zone区域的每CPU成员pageset的初始化

======================================================================================



三种内存模型：
flat memory： 适用于连续物理内存或大部分连续物理内存的非NUMA系统；用一个全局mem_map数组映射整过物理内存，即使是空洞内存，也需要分配struc page结构体，只不过不会被初始化
			使用时需要通过pfn_valid来进行检测，会浪费一些struct page；
discontiguous memory： 物理内存存在空洞，已被弃用；
sparse memory： 物理内存存在空洞，支持内存热拔插，以struct mem_section(1G)为单位进行管理
https://lwn.net/Articles/789304/





SECTION_SIZE_BITS = 30
PAGE_SHIFT = 12
PFN_SECTION_SHIFT = SECTION_SIZE_BITS - PAGE_SHIFT = 18
PAGES_PER_SECTION = 1UL << PFN_SECTION_SHIFT = 0x40000 = 256K = 262144

MAX_PHYSMEM_BITS = CONFIG_ARM64_PA_BITS = 48
SECTIONS_SHIFT = MAX_PHYSMEM_BITS - SECTION_SIZE_BITS = 18

SECTIONS_PER_ROOT = PAGE_SIZE(0x1000) / sizeof(struct mem_section)(0x10) = 0x100 = 256

pageblock_order=9
NR_PAGEBLOCK_BITS=4
1UL << (PFN_SECTION_SHIFT - pageblock_order) = 512
SECTION_BLOCKFLAGS_BITS = ((1UL << (PFN_SECTION_SHIFT - pageblock_order)) * NR_PAGEBLOCK_BITS) = 2048
usemap_size = (2048 / 64) = 32 * 8 = 256


ARM64_SWAPPER_USES_SECTION_MAPS = 1
#define vmemmap			((struct page *)VMEMMAP_START - (memstart_addr >> PAGE_SHIFT))


#define __pfn_to_page(pfn)	(vmemmap + (pfn))
#define __page_to_pfn(page)	(unsigned long)((page) - vmemmap)

#define page_to_pfn __page_to_pfn
#define pfn_to_page __pfn_to_page


/proc/pagetypeinfo可以查看zone中内存的类型type
enum zone_type {
	ZONE_DMA32,				内存在0x00000000~0xFFFFFFFF范围内的都属于这个zone;
	ZONE_NORMAL,			内存大于0xFFFFFFFF的属于这个zone
	ZONE_MOVABLE,			用于优化内存迁移场景，该zone内存都一定可以迁移(优化了普通zone中存在不可迁移的内存，这增加了迁移的难度，也加剧了内存碎片化)； 优化内存热拔插，
	__MAX_NR_ZONES
};

默认 MAX_NUMNODES = 4


========================================================================================
if (pfn_valid(start_pfn))							//页号的有效性检查
	struct page *page = pfn_to_page(start_pfn)		//页号找到对应的page地址： 
	






========================================================================================


bootmem_init()
	...
	early_memtest(min << PAGE_SHIFT, max << PAGE_SHIFT)								//需要再cmdline中设置memtest参数才会处理相关逻辑： 测试内存是否有效，无效内存将会memblock_reserve，一般uboot中已经测试？
	...
	arm64_numa_init()
		if (!numa_off)																//cmdline中没有设置的话则默认numa_off=0
			...
			if (acpi_disabled && !numa_init(of_numa_init)) ==> numa_init(of_numa_init))
				...
				numa_alloc_distance()												//主要是初始化 numa_distance 数组(用于numa_register_nodes使用)，本地node，则默认初始化为10，如果是远端node，则默认初始化为20；接下来解析设备树时若有numa-distance的节点则会再次设置该结构体
				of_numa_init()
					of_numa_parse_cpu_nodes()										//解析是否有“numa-node-id”属性的CPU节点,设置相关属性
					of_numa_parse_memory_nodes()									//解析是否有“numa-node-id”属性的memory节点，设置对应内存所属的节点nid
					...
					of_numa_parse_distance_map()
						np = of_find_compatible_node(NULL, NULL, "numa-distance-map-v1");		//查找是否有解析是否有“numa-distance-map-v1”属性的节点
						if (np)
							ret = of_numa_parse_distance_map_v1(np);							//有的话就将根据节点信息重新设置 numa_distance 数组
				if (nodes_empty(numa_nodes_parsed))										//一般嵌入式平台没有其他的node，将会退出，走后面的dummy_numa_init初始化
					goto out_free_distance;
			
				numa_register_nodes()													//非服务器的芯片很少会走到这
			numa_init(dummy_numa_init)
				dummy_numa_init()														//设置每块内存的 nid(numa_id)
				numa_register_nodes()													//把各个内存块与NUMA节点关联
					setup_node_data(nid, start_pfn, end_pfn)							//申请用于记录内存node的 pg_data_t 结构体地址，并保存相关信息
						...
						memblock_phys_alloc_try_nid(nd_size, SMP_CACHE_BYTES, nid)
						pr_info("NODE_DATA [mem %#010Lx-%#010Lx]\n", nd_pa, nd_pa + nd_size - 1)	//将打印出保存pg_data_t结构体的内存
						...
				setup_node_to_cpumask_map()												//把各个CPU core与NUMA节点关联

	memblocks_present()
		memory_present(memblock_get_region_node(reg), memblock_region_memory_base_pfn(reg), memblock_region_memory_end_pfn(reg));
			...																			//定义了CONFIG_SPARSEMEM_EXTREME则说明用的是动态申请内存，否则是静态定义的为二维数组
			mem_section = memblock_alloc(sizeof(struct mem_section*) * NR_SECTION_ROOTS, 1 << (INTERNODE_CACHE_SHIFT))	// 888 申请section(1G)数组指针数组的内存(用于管理1G粒度的内存)，并没有分配实际结构体的内存，这里因为已经把所有物理内存映射到虚拟地址的线性映射区，所以里面可以直接用phys_to_virt获取虚拟地址访问；对比early_pgtable_alloc，需要临时用PTE的虚拟地址映射才能访问
			...
			mminit_validate_memmodel_limits(&start, &end)								//检查内存的有效性
			...
			for (pfn = start; pfn < end; pfn += PAGES_PER_SECTION)						// PAGES_PER_SECTION * 4K 即1G大小，这里的值都是fpn
				unsigned long section = pfn_to_section_nr(pfn)							// 从这就可以看出section是从ddr的0地址开始，0x0~0x40000000的sectionid=0，0x40000000~0x80000000的sectionid=1，依次类推,,,

				sparse_index_init(section, nid)
					if (mem_section[root])												//判断指针是否存在
					section = sparse_index_alloc(nid)									//申请struct mem_section结构体的内存
					mem_section[root] = section											//地址保存到mem_section指针数组中
				set_section_nid(section, nid)											//将sectionid对应的哪个nid的内存(UMA系统的话就都是0)保存在section_to_node_table全局数组中，大小1024
				s = __nr_to_section(section)											//SECTIONS_PER_ROOT(0x100)大小为一维数组大小，二维数组的的id还是等于1,对比H5，0的对应的0x0~0x40000000仍然空出来了
				if (!ms->section_mem_map) {												//设置section_mem_map
					ms->section_mem_map = sparse_encode_early_nid(nid) |				// ms->section_mem_map = nid << 3 | SECTION_IS_ONLINE | SECTION_MARKED_PRESENT
									SECTION_IS_ONLINE;
					section_mark_present(ms);

	sparse_init()
		unsigned long pnum_begin = first_present_section_nr()							//获取mem_section数组第一个存在元素的num
		nid_begin = sparse_early_nid(__nr_to_section(pnum_begin))						//获取第一个mem_section对应内存所属的nid(NUMA_id)
		...
		set_pageblock_order()															// H5中未实现
		for_each_present_section_nr(pnum_begin + 1, pnum_end)							// 获取最后一个pnum_end值，H5中pnum_end=-1,不会进入里面循环
		...
		sparse_init_nid(nid_begin, pnum_begin, pnum_end, map_count)
			...
			usemap = sparse_early_usemaps_alloc_pgdat_section(NODE_DATA(nid), usemap_size() * map_count)			// mem_section->pageblock_flags指针指向的内存256字节
			sparse_buffer_init(map_count * section_map_size(), nid)													// 申请一个mem_section中所有(262144,256K*map_count)个struct page(64)结构体需要的内存(总共16M内存)，地址存在sparsemap_buf全局指针上；后续和VMEMMAP_START虚拟地址建立页表映射；目前是通过这个虚拟地址++pfn来访问page地址
				sparsemap_buf = memblock_alloc_try_nid_raw(size, PAGE_SIZE, addr, MEMBLOCK_ALLOC_ACCESSIBLE, nid);
				sparsemap_buf_end = sparsemap_buf + size;	
			for_each_present_section_nr(pnum_begin, pnum)															//循环处理所有 mem_section 结构体
				...
				map = sparse_mem_map_populate(pnum, nid, NULL)
					...
					map = pfn_to_page(pnum * PAGES_PER_SECTION)														//实际上获取VMEMMAP_START的虚拟地址
					start = (unsigned long)map;
					end = (unsigned long)(map + PAGES_PER_SECTION)													// 888 指针加法，实际是 end = map + PAGES_PER_SECTION*sizeof(struct page)==> 0xffff7e0001000000 = 0xffff7e0000000000 + 0x40000*64
					vmemmap_populate(start, end, nid, altmap)														// 3级映射，指定VMEMMAP_START虚拟地址，申请2M内存与指定的虚拟地址做映射
					do {
						next = pmd_addr_end(addr, end)																// 3级映射，2M粒度，即相当于32K个struct page一组，next = addr + 0x200000
						pgdp = vmemmap_pgd_populate(addr, node);
							pgd_t *pgd = pgd_offset_k(addr)															//获取保存下一级PUD物理地址的虚拟地址(PGD+offset)
							if (pgd_none(*pgd))																		//若改虚拟地址是空的话
								void *p = vmemmap_alloc_block_zero(PAGE_SIZE, node)									//通过memblock申请一页物理地址
								pgd_populate(&init_mm, pgd, p)														//将申请的物理地址保存在PGD+offset的虚拟地址中，返回(PGD+offset)的虚拟地址
						pudp = vmemmap_pud_populate(pgdp, addr, node)												//同上， 先获取保存下二级PMD物理地址的虚拟地址(PUD+offset)
																													虚拟地址为空话memblock申请一页物理地址，然后把物理地址保存在PUD+offset虚拟地址中，返回(PUD+offset)虚拟地址
						pmdp = pmd_offset(pudp, addr)																//获取保存3级PTE的物理地址的虚拟地址(PMD+offset)
						if (pmd_none(READ_ONCE(*pmdp)))																//判断虚拟地址中是否为空
							p = vmemmap_alloc_block_buf(PMD_SIZE, node)
								ptr = sparse_buffer_alloc(size)														//通过上面已经申请好的内存 sparsemap_buf 拆分获取当前需要的内存
							pmd_set_huge(pmdp, __pa(p), __pgprot(PROT_SECT_NORMAL))
								pmd_t new_pmd = pfn_pmd(__phys_to_pfn(phys), sect_prot)								//设置内存权限配置
								...
								set_pmd(pmdp, new_pmd)																//将申请的物理地址保存到(PMD+offset)虚拟地址中
						...
					} while (addr = next, addr != end);
				check_usemap_section_nr(nid, usemap)																//H5默认未开启
				sparse_init_one_section(__nr_to_section(pnum), pnum, map, usemap)
					ms->section_mem_map &= ~SECTION_MAP_MASK														清除除bit[0~2]其他所有bit									
					ms->section_mem_map |= sparse_encode_mem_map(mem_map, pnum) | SECTION_HAS_MEM_MAP
					ms->pageblock_flags = usemap
	
			sparse_buffer_fini()																					//释放未使用完的sparsemap_buf内存


	zone_sizes_init(min, max)
		max_zone_pfns[ZONE_DMA32] = PFN_DOWN(max_zone_dma_phys()) = PFN_DOWN(min(0 + (1ULL << 32), memblock_end_of_DRAM())) = PFN_DOWN(memblock_end_of_DRAM());			//计算这2个zone的最大值
		max_zone_pfns[ZONE_NORMAL] = PFN_DOWN(memblock_end_of_DRAM())
		free_area_init_nodes(max_zone_pfns)
			...
			start_pfn = find_min_pfn_with_active_regions()
				find_min_pfn_for_node(MAX_NUMNODES)																//从所有NUMA节点内存中找到最小地址的内存，参数MAX_NUMNODES意思查看所有NUMA节点
			for (i = 0; i < MAX_NR_ZONES; i++) {																//获取每个zone的最大最小值保存在arch_zone_lowest_possible_pfn、arch_zone_highest_possible_pfn数组中
				end_pfn = max(max_zone_pfn[i], start_pfn)
				arch_zone_lowest_possible_pfn[i] = start_pfn
				arch_zone_highest_possible_pfn[i] = end_pfn
				start_pfn = end_pfn																				//最大值等于最小值说明这个zone为空
			...
			find_zone_movable_pfns_for_nodes()																	//内核启动参数movablecore用于指定此区域的大小。
																												//内核参数kernelcore也可用于指定非可移动内存的大小，剩余的内存都是可移动内存。
																												//如果两者同时指定的话，则会优先保证非可移动内存的大小至少有kernelcore这么大。
																												//如果两者都没指定，则可移动内存大小为0
			...
			pr_info("Zone ranges:\n");
			for (i = 0; i < MAX_NR_ZONES; i++)																	//打印各zone的信息
			...
			pr_info("Movable zone start for each node\n")														//打印movable zone信息，cmdline没有设置的话则会空
			for (i = 0; i < MAX_NUMNODES; i++) 	
			...
			pr_info("Early memory node ranges\n");																//打印所有NUMA节点内存信息
			for_each_mem_pfn_range(i, MAX_NUMNODES, &start_pfn, &end_pfn, &nid)
			...
			for_each_online_node(nid)
				free_area_init_node(nid, NULL, find_min_pfn_for_node(nid), NULL)								// 888 最重要的处理，传入NUMA_id及最小内存地址页数
					...																							// 配置 pg_data_t 结构体信息，打印该NUMA节点内存地址范围
					calculate_node_totalpages(pgdat, start_pfn, end_pfn, zones_size, zholes_size)				// 计算该NUMA_id总的页数，减去了该范围内存可能存在的空洞
						...
						zone->spanned_pages = size																// 该zone总共的页面数，包括空洞区域
						zone->present_pages = real_size															// 该zone总共可用的页面数，不是去掉已经被使用，是去掉空洞区域的
						...
						pgdat->node_spanned_pages = totalpages													// 该NUMA_id总共的页面数，包括空洞区域
						pgdat->node_present_pages = realtotalpages												// 该NUMA_id总共可用的页面数，不是去掉已经被使用，是去掉空洞区域的
					...
					free_area_init_core(pgdat)																	//主要完成 pg_data_t 结构体字段初始化，并初始化它所管理的各个zone
						...
						pgdat_init_internals(pgdat)																//初始化 pg_data_t 结构体内部锁和队列
						...
						for (j = 0; j < MAX_NR_ZONES; j++)														
							...
							size = zone->spanned_pages
							freesize = zone->present_pages
							...
							memmap_pages = calc_memmap_size(size, freesize)										//计算该zone所需的所有struct page结构所占的页面数(16M)
							freesize -= memmap_pages
							printk(KERN_DEBUG "  %s zone: %lu pages used for memmap\n", zone_names[j], memmap_pages)
							...
							freesize -= dma_reserve
							printk(KERN_DEBUG "  %s zone: %lu pages reserved\n", zone_names[0], dma_reserve)
							...
							nr_kernel_pages = nr_all_pages += freesize											//arm64情况下没有CONFIG_HIGHMEM，所以nr_kernel_pages等于nr_all_pages
							zone_init_internals(zone, j, nid, freesize)
								atomic_long_set(&zone->managed_pages, freesize)									//zone->managed_pages = freesize,把各个zone可用内存赋值到zone->managed_pages
								...																				//初始化zone结构体使用的各种锁资源
								zone_pcp_init(zone)																// 888 配置zone结构体pageset内存，伙伴算法中将使用，该内存为percpu内存
									zone->pageset = &boot_pageset
							...
							if (!size)
								continue																		//这里处理各个zone信息，若size为0,,则不处理下面操作
							set_pageblock_order()																//H5为空函数
							setup_usemap(pgdat, zone, zone_start_pfn, size)										//同上，配置了CONFIG_SPARSEMEM情况下改内存 mem_section 结构体中
							init_currently_empty_zone(zone, zone_start_pfn, size)								// 888 初始化zone的free_area列表
								zone_init_free_lists(zone)
									for_each_migratetype_order(order, t)
										INIT_LIST_HEAD(&zone->free_area[order].free_list[t])					// 888 先循环Migrate类型，再循环位阶
										zone->free_area[order].nr_free = 0										// 888
							memmap_init(size, nid, j, zone_start_pfn)
								memmap_init_zone(size, nid, zone, start_pfn, MEMMAP_EARLY, NULL)
									...
									for (pfn = start_pfn; pfn < end_pfn; pfn++)
										if (context == MEMMAP_EARLY)											//先关内存检查、过滤
											if (!early_pfn_valid(pfn))											//检查有效性
											if (!early_pfn_in_nid(pfn, nid))									//未配置CONFIG_NODES_SPAN_OTHER_NODES,函数为空
											if (overlap_memmap_init(zone, &pfn))								//H5没有move zone,无处理
											if (defer_init(nid, pfn, end_pfn))									//无处理
										page = pfn_to_page(pfn)													// 888 通过过指定的VMEMMAP_START虚拟地址+pfn,找到pfn对应的struct page结构地址
										__init_single_page(page, pfn, zone, nid)								// 888 初始化这页内存对应的struct page结构
										...
										set_pageblock_migratetype(page, MIGRATE_MOVABLE)						//先将所有页都配置为可以移动，MIGRATE_MOVABLE







numa:
https://zhou-yuxin.github.io/articles/2018/Linux%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E2%80%94%E2%80%94%E8%8E%B7%E5%8F%96%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80%E3%80%81%E5%88%92%E5%88%86%E5%86%85%E5%AD%98%E5%8C%BA%E4%B8%8E%E5%88%9B%E5%BB%BANUMA%E8%8A%82%E7%82%B9/index.html

在NUMA架构下，每一个Node都会对应一个struct pglist_data，在UMA架构中只会使用唯一的一个struct pglist_data结构

struct pglist_data 关键字段
	struct zone node_zones[];           	//对应的ZONE区域，比如ZONE_DMA，ZONE_NORMAL等
	struct zonelist_node_zonelists[];

	unsigned long node_start_pfn;           //节点的起始内存页面帧号
	unsigned long node_present_pages;    	//该NUMA_id总共可用的页面数，不是去掉已经被使用，是去掉空洞区域的
	unsigned long node_spanned_pages;  		//总共的页面数，包括有空洞的区域

	wait_queue_head_t kswapd_wait;        	//页面回收进程使用的等待队列
	struct task_struct *kswapd;             //页面回收进程

=============================================

struct zone 关键字段
	unsigned long watermark[];          	//水位值，WMARK_MIN/WMARK_LOV/WMARK_HIGH，页面分配器和kswapd页面回收中会用到
	long lowmem_reserved[];             	//zone中预留的内存
	struct pglist_data *zone_pgdat;     	//执行所属的pglist_data
	struct per_cpu_pageset *pageset;  		// 888 Per-CPU上的页面，减少自旋锁的争用

	unsigned long zone_start_pfn;       	//ZONE的起始内存页面帧号
	unsigned long managed_pages;    		//present_pages的基础上，减去改zone中struct page所使用的，减去dma_reserve，剩余可以用来真正管理分配给其他人的内存页数  (被Buddy System管理的页面数量，present_pages-memmap_pages-dma_reserve的内存)；后续mm_init(),会重新统计，整体内存减去所有reserved的内存
	unsigned long spanned_pages;     		//ZONE中总共的页面数，包含空洞的区域
	unsigned long present_pages;      		//ZONE里实际管理的页面数量，不是去掉已经被使用，是去掉空洞区域的

	struct free_area free_area[MAX_ORDER];  // 888 管理空闲页面的列表

struct per_cpu_pageset {
	struct per_cpu_pages pcp;
	...
};

struct per_cpu_pages {
	int count;		/* number of pages in the list */
	int high;		/* high watermark, emptying needed */
	int batch;		/* chunk size for buddy add/remove */
	/* Lists of pages, one per migrate type stored on the pcp-lists */
	struct list_head lists[MIGRATE_PCPTYPES];	//维护0阶内存，只维护 MIGRATE_UNMOVABLE，MIGRATE_MOVABLE，MIGRATE_RECLAIMABLE类型的内存
};

struct free_area {
	struct list_head	free_list[MIGRATE_TYPES];//维护所有位阶，所有类型的内存
	unsigned long		nr_free;
};

=============================================

该系统有1024个struct mem_section结构体指针，因为是1G内存，所以第一个指针有指向具体的内存，指向有256个该结构体数组的内存；256个中的第一个数组管理这这1G的内存
struct mem_section {
	unsigned long section_mem_map;
	unsigned long *pageblock_flags;
};



