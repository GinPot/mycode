/*
Copyright 2001, QNX Software Systems Ltd. All Rights Reserved
 
This source code has been published by QNX Software Systems Ltd. (QSSL).
However, any use, reproduction, modification, distribution or transfer of
this software, or any software which includes or is based upon any of this
code, is only permitted under the terms of the QNX Realtime Plaform End User
License Agreement (see licensing.qnx.com for details) or as otherwise
expressly authorized by a written license agreement from QSSL. For more
information, please email licensing@qnx.com.
*/
/* 
 * ARM specific dynamic linker support
 */

extern struct syspage_entry *_syspage_ptr;
extern struct cpupage_entry *_cpupage_ptr;
extern void *__SysCpupageGet(int index);
extern void *__SysCpupageSet(int index, int value);

/* 
 * This is the _start_ function, the entry point into the program
 * when linked with the shared lib.
 *
 * FIXME: need to deal with fini/atexit stuff
 */
void _start_(void);
__asm__ (
	".globl \t _start_\n"
	"_start_:	mov		r0, sp;"
	"			bl		ldd;"
	"			mov		r1, r0;"
#ifdef	__PIC__
	"			ldr		sl, .L1;"
	"			add		sl, pc, sl;"
	".L0:		ldr		r0, .L1+4;"
	"			ldr		r0, [sl, r0];"
	"			mov		pc, r1;"
	".L1:		.word	_GLOBAL_OFFSET_TABLE_ - (.L0+4);"
	"			.word	_do_exit_fini(GOT);"
#else
	"			ldr		r0, .L1;"
	"			mov		pc, r1;"
	".L1:		.word	_do_exit_fini;"
#endif
	"\t.type \t _start_,function\n"
	"\t.size \t _start_,.-_start_\n"
);

/*
 * lookup() uses the % operator, so we need a static version here.
 * This does not cope well with x % 0 (but then neither does libgcc.a)
 */
void __umodsi3();
__asm__ (
	"__umodsi3:	cmp		r1, #0;"
	"			moveq	pc, lr;"
	"			mov		r3, #1;"
	"			cmp		r0, r1;"
	"			movcc	pc, lr;"
	"Loop1:		cmp		r1, #0x10000000;"
	"			cmpcc	r1, r0;"
	"			movcc	r1, r1, lsl #4;"
	"			movcc	r3, r3, lsl #4;"
	"			bcc		Loop1;"
	"Lbignum:	cmp		r1, #0x80000000;"
	"			cmpcc	r1, r0;"
	"			movcc	r1, r1, lsl #1;"
	"			movcc	r3, r3, lsl #1;"
	"			bcc		Lbignum;"
	"Loop3:		mov		r2, #0;"
	"			cmp		r0, r1;"
	"			subcs	r0, r0, r1;"
	"			cmp		r0, r1, lsr #1;"
	"			subcs	r0, r0, r1, lsr #1;"
	"			orrcs	r2, r2, r3, ror #1;"
	"			cmp		r0, r1, lsr #2;"
	"			subcs	r0, r0, r1, lsr #2;"
	"			orrcs	r2, r2, r3, ror #2;"
	"			cmp		r0, r1, lsr #3;"
	"			subcs	r0, r0, r1, lsr #3;"
	"			orrcs	r2, r2, r3, ror #3;"
	"			mov		ip, r3;"
	"			cmp		r0, #0;"
	"			movnes	r3, r3, lsr #4;"
	"			movne	r1, r1, lsr #4;"
	"			bne		Loop3;"
	"			ands	r2, r2, #0xe0000000;"
	"			moveq	pc, lr;"
	"			tst		r2, ip, ror #3;"
	"			addne	r0, r0, r1, lsr #3;"
	"			tst		r2, ip, ror #2;"
	"			addne	r0, r0, r1, lsr #2;"
	"			tst		r2, ip, ror #1;"
	"			addne	r0, r0, r1, lsr #1;"
	"			mov		pc, lr;"
);
				
/*
 * This is the bind function used for lazy binding
 */
void
bind_func(void)
{
	/*
	 * FIXME: placeholder for now
	 */
}

/*
 * Relocate all local GOT entries
 */
static void
relocate_local_got(struct object *obj)
{
	obj->got[0] = RELOC(obj, obj->got[0]);
	obj->got[1] = (uintptr_t) obj;
	obj->got[2] = (uintptr_t) bind_func;
}


/*
 * And this processes the relocation table.
 */
static int
resolve_rels(const Elf32_Rel *rel, int nrel, struct objlist *ol, int mode)
{
	struct object				*obj = ol->object;
	const list_head_t			*this = ol->root;
	struct objlist				o;
	int							ret = 0;

	/*
	 * if this is a DT_SYMBOLIC object, then make sure it gets searched
	 * first, by temporarily placing it at the head of the objlist
	 */
	if (obj->flags & OBJFLAG_SYMBOLIC) {
		o.object = obj;
		list_append(this, &o);
	}

	while (nrel--) {
		const Elf32_Sym	*sym = &obj->symbols[ELF32_R_SYM(rel->r_info)];
		const char		*name = obj->strings + sym->st_name;
		int				rtype = ELF32_R_TYPE(rel->r_info);
		unsigned long	*dst = RELOCP(obj, rel->r_offset);
		const Elf32_Sym	*tsym;
		struct object	*tobj;

		if ( rtype == R_ARM_NONE ) {
			/* nothing to do... */
			rel++;
			continue;
		}
		/*
		 * FIXME: this needs to be checked:
		 *
		 * when searching for the source of a copy relocation don't
		 * look for the symbol within the object being processed
		 *
		 * when processing jump slot relocations, the PLT symbol should
		 * not be used.  The PLT symbol is detected by having
		 * st_shndx == SHN_UNDEF and type == STT_FUNC and st_value != 0.
		 * If the address of a function AND a call is taken by an
		 * object to a function, then the linker should ONLY generate
		 * an R_ARM_32 relocation so that the GOT entry will point to
		 * the PLT entry for the function.  These PLT symbols should
		 * only exist in the executable.
		 *
		 * Another thing we do here is to resolve the internal relative
		 * relocs on the first bootstrapping pass (for libc.so). These
		 * obviously don't get done again. We also have the ability to reverse
		 * the global relative relocations, to "undo" our bootstrapping phase
		 * and resolve the symbols in libc.so in the right context. For other
		 * relocations, we don't need to undo them since there are no addends.
		 */

	   if ((rtype == R_ARM_RELATIVE || ((mode == RTLD_LAZY) && rtype == R_ARM_JMP_SLOT))
			   && !(obj->flags & OBJFLAG_RELSDONE)) {
			   *dst = RELOC(obj, *dst);
	   } else if ((tsym = lookup_global(name, this, rtype == R_ARM_COPY ? obj : 0,
					   rtype == R_ARM_JMP_SLOT, &tobj)) ||
                       (ELF32_ST_BIND(sym->st_info) == STB_WEAK)) {
			   uintptr_t	val = tsym ? RELOC(tobj, tsym->st_value) : 0;

			   if (rtype == R_ARM_JMP_SLOT) {
					   *dst = val;
			   } else if (rtype == R_ARM_GLOB_DAT) {
					   *dst = val;
			   } else if (rtype == R_ARM_ABS32) {
					   *dst += (unsigned) RELOFFSET((obj->flags & OBJFLAG_REVERSED), (val));
			   } else if (rtype == R_ARM_COPY && tsym) {
					   xmemcpy(dst, (void *)val, tsym->st_size < sym->st_size ?
							   tsym->st_size : sym->st_size);
			   } else if (tsym) {
					write(STDERR_FILENO,"unknown relocation type\n",24);
					ret = -1;
			   } else {
					write(STDERR_FILENO,"bad weak relocation type\n",25);
					ret = -1;
			   }
	   } else {
			if(rtype != R_ARM_RELATIVE && (!((mode == RTLD_LAZY) && (rtype == R_ARM_JMP_SLOT)))) {
				write(STDERR_FILENO, "unknown symbol: ", 16);
				write(STDERR_FILENO, name, strlen(name));
				write(STDERR_FILENO, "\n", 1);
				ret = -1;
			}
	   }
	   rel++;
	}

	/*
	 * if the object was previously placed at the list head, remove it
	 */
	if (obj->flags & OBJFLAG_SYMBOLIC) {
		list_delete(&o);
	}
	return ret;
}


static int
resolve(const list_head_t *this, int mode)
{
	unsigned long		vec[50];
	struct objlist		*o;
	int					ret = 0;

	list_backward(this, o) {
		struct object		*obj = o->object;

		vector_decode(vec, sizeof vec / sizeof *vec, obj->dynamic, 0);
		if (!(obj->flags & OBJFLAG_RESOLVED)) {
			if (vec[DT_REL] != -1) {
				if(resolve_rels((Elf32_Rel *)RELOCP(obj, vec[DT_REL]),
						vec[DT_RELSZ] / sizeof(Elf32_Rel), o, RTLD_NOW)) {
					ret = -1;
				}
			}
			if (vec[DT_JMPREL] != -1) {
				if(resolve_rels((Elf32_Rel *)RELOCP(obj, vec[DT_JMPREL]),
					vec[DT_PLTRELSZ] / sizeof(Elf32_Rel), o, mode)) {
					ret = -1;
				}
			}
		}
		/* The internal relative relocs are done, don't do them again. */
		obj->flags |= (OBJFLAG_RELSDONE | OBJFLAG_RESOLVED);
	}

	/*
	 * Should now be safe to call CpuSyspageGet to setup syspage...
	 * This is needed because the rest of ldd may call fn. which need these.
	 */
	_cpupage_ptr = __SysCpupageGet(CPUPAGE_ADDR);
	_syspage_ptr = __SysCpupageGet(CPUPAGE_SYSPAGE);

	return ret;
}
